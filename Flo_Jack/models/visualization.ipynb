{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torch.nn import BCELoss\n",
    "\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from pathlib import *\n",
    "import os\n",
    "import tqdm\n",
    "import argparse\n",
    "import json\n",
    "\n",
    "from models.tcn import MS_TCN, SS_TCN\n",
    "from dataset.VolvoDataset import VolvoDatasetPart1, VolvoDatasetPart2\n",
    "from utils.ContinuityCrossEntropyLoss import ContinuityCrossEntropyLoss\n",
    "from utils.StatsComputer import StatsComputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.94"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = torch.tensor([0.1, 0.2, 0, 0.4, 0.5])\n",
    "tensor_1 = torch.tensor([0.1, 0.2, 0.3, 0.4, 0.5])\n",
    "\n",
    "def tensor_to_vector(tensor):\n",
    "    tensor = tensor * 10\n",
    "    tensor = torch.round(tensor)\n",
    "    tensor\n",
    "\n",
    "    # for each number, create a tensor with 10 elements, with (1 - number) being 0 and number being 1\n",
    "    list = []\n",
    "    for n in tensor:\n",
    "        list.append(torch.cat([torch.zeros(int(10 - n)), torch.ones(int(n))]))\n",
    "\n",
    "    return torch.stack(list)\n",
    "\n",
    "tensor = tensor_to_vector(tensor)\n",
    "tensor_1 = tensor_to_vector(tensor_1)\n",
    "\n",
    "# count total accuracy\n",
    "\n",
    "correct = torch.eq(tensor, tensor_1).sum().item()\n",
    "total = tensor.numel()\n",
    "correct / total\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 1., 1.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 1., 1., 1.],\n",
       "         [0., 0., 0., 0., 0., 0., 1., 1., 1., 1.],\n",
       "         [0., 0., 0., 0., 0., 1., 1., 1., 1., 1.]]),\n",
       " tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 1., 1., 1.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 1., 1., 1.],\n",
       "         [0., 0., 0., 0., 0., 0., 1., 1., 1., 1.],\n",
       "         [0., 0., 0., 0., 0., 1., 1., 1., 1., 1.]]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor, tensor_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = argparse.Namespace(\n",
    "    seed=13_04_2000,\n",
    "    test_only=False,\n",
    "    load_model=\"\",\n",
    "    batch_size=256,\n",
    "    num_epochs=30,\n",
    "    learning_rate=0.0005,\n",
    "    lr_scheduler_gamma=0.8,\n",
    "    lr_scheduler_step=1,\n",
    "    patience_epochs=7,\n",
    "    disable_cuda=False,\n",
    "    data_path=r\"/data1/malto/volvo_ecml_2024\",\n",
    "    train_csv=r\"train_gen1.csv\",\n",
    "    test_csv=r\"public_X_test.csv\",\n",
    "    variants_csv=r\"variants.csv\",\n",
    "    tcnn_weights=r\"./\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = args\n",
    "\n",
    "np.random.seed(args.seed)\n",
    "torch.manual_seed(args.seed)\n",
    "\n",
    "### Get important paths\n",
    "dataset_path = args.data_path \n",
    "variants_path = os.path.join(dataset_path, args.variants_csv)\n",
    "train_data_path = os.path.join(dataset_path, args.train_csv)\n",
    "test_data_path = os.path.join(dataset_path, args.test_csv)\n",
    "weights_path = args.tcnn_weights\n",
    "os.makedirs(weights_path, exist_ok=True)\n",
    "\n",
    "### Get dataset and model type\n",
    "train_data_path = os.path.join(args.data_path, \"train_gen1.csv\")\n",
    "test_data_path = os.path.join(args.data_path, \"public_X_test.csv\")\n",
    "variants_path = os.path.join(args.data_path, \"variants.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7280/7280 [00:00<00:00, 48583.81it/s]\n",
      "100%|██████████| 3359/3359 [00:00<00:00, 104593.70it/s]\n"
     ]
    }
   ],
   "source": [
    "train_dataset = VolvoDatasetPart1(data_path=train_data_path, variants_path=variants_path)\n",
    "processor = train_dataset.get_processor()\n",
    "label_encoder = processor.risk_encoder\n",
    "\n",
    "train_dataset, validation_dataset = train_dataset.split_train_validation()\n",
    "\n",
    "test_dataset = VolvoDatasetPart1(data_path=test_data_path, variants_path=variants_path, test=True)\n",
    "test_dataset.set_processor(processor) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, x_static, y = train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 0.])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timesteps</th>\n",
       "      <th>ChassisId_encoded</th>\n",
       "      <th>gen</th>\n",
       "      <th>risk_level</th>\n",
       "      <th>af1__0</th>\n",
       "      <th>af1__1</th>\n",
       "      <th>af1__2</th>\n",
       "      <th>af1__3</th>\n",
       "      <th>af1__4</th>\n",
       "      <th>af1__6</th>\n",
       "      <th>...</th>\n",
       "      <th>f__232</th>\n",
       "      <th>f__233</th>\n",
       "      <th>f__234</th>\n",
       "      <th>f__235</th>\n",
       "      <th>f__237</th>\n",
       "      <th>f__238</th>\n",
       "      <th>f__239</th>\n",
       "      <th>f__240</th>\n",
       "      <th>f__241</th>\n",
       "      <th>f__242</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4953.0</td>\n",
       "      <td>gen1</td>\n",
       "      <td>High</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.694897</td>\n",
       "      <td>-5.827349</td>\n",
       "      <td>-1.449851</td>\n",
       "      <td>-0.350315</td>\n",
       "      <td>1.394857</td>\n",
       "      <td>0.192880</td>\n",
       "      <td>-0.495562</td>\n",
       "      <td>-0.928794</td>\n",
       "      <td>-0.214402</td>\n",
       "      <td>-0.090670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4955.0</td>\n",
       "      <td>gen1</td>\n",
       "      <td>Low</td>\n",
       "      <td>0.000322</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.057749</td>\n",
       "      <td>8.627059e-08</td>\n",
       "      <td>0.029966</td>\n",
       "      <td>0.019837</td>\n",
       "      <td>...</td>\n",
       "      <td>0.121147</td>\n",
       "      <td>0.230757</td>\n",
       "      <td>0.280036</td>\n",
       "      <td>-0.206586</td>\n",
       "      <td>-0.088550</td>\n",
       "      <td>-0.836415</td>\n",
       "      <td>-0.484087</td>\n",
       "      <td>0.320285</td>\n",
       "      <td>2.311401</td>\n",
       "      <td>-0.026043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4955.0</td>\n",
       "      <td>gen1</td>\n",
       "      <td>Low</td>\n",
       "      <td>0.000322</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.057749</td>\n",
       "      <td>8.627059e-08</td>\n",
       "      <td>0.029966</td>\n",
       "      <td>0.019837</td>\n",
       "      <td>...</td>\n",
       "      <td>0.121147</td>\n",
       "      <td>0.230757</td>\n",
       "      <td>0.280036</td>\n",
       "      <td>-0.206586</td>\n",
       "      <td>-0.091570</td>\n",
       "      <td>-0.841418</td>\n",
       "      <td>-0.472325</td>\n",
       "      <td>0.322941</td>\n",
       "      <td>2.284491</td>\n",
       "      <td>-0.026732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>4955.0</td>\n",
       "      <td>gen1</td>\n",
       "      <td>Low</td>\n",
       "      <td>0.000322</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.057749</td>\n",
       "      <td>8.627059e-08</td>\n",
       "      <td>0.029966</td>\n",
       "      <td>0.019837</td>\n",
       "      <td>...</td>\n",
       "      <td>0.121147</td>\n",
       "      <td>0.230757</td>\n",
       "      <td>0.280036</td>\n",
       "      <td>-0.206586</td>\n",
       "      <td>-0.029233</td>\n",
       "      <td>-0.817824</td>\n",
       "      <td>-0.509273</td>\n",
       "      <td>0.306841</td>\n",
       "      <td>2.266275</td>\n",
       "      <td>-0.027429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0</td>\n",
       "      <td>4955.0</td>\n",
       "      <td>gen1</td>\n",
       "      <td>Low</td>\n",
       "      <td>0.000322</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.057749</td>\n",
       "      <td>8.627059e-08</td>\n",
       "      <td>0.029966</td>\n",
       "      <td>0.019837</td>\n",
       "      <td>...</td>\n",
       "      <td>0.121147</td>\n",
       "      <td>0.230757</td>\n",
       "      <td>0.280036</td>\n",
       "      <td>-0.206586</td>\n",
       "      <td>-0.002841</td>\n",
       "      <td>-0.808023</td>\n",
       "      <td>-0.513796</td>\n",
       "      <td>0.309057</td>\n",
       "      <td>2.237995</td>\n",
       "      <td>-0.028150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157432</th>\n",
       "      <td>12.0</td>\n",
       "      <td>102478.0</td>\n",
       "      <td>gen1</td>\n",
       "      <td>High</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.694897</td>\n",
       "      <td>-5.827349</td>\n",
       "      <td>-1.449851</td>\n",
       "      <td>-0.350315</td>\n",
       "      <td>-0.513768</td>\n",
       "      <td>-2.615375</td>\n",
       "      <td>1.035627</td>\n",
       "      <td>1.758682</td>\n",
       "      <td>0.122545</td>\n",
       "      <td>-0.088263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157433</th>\n",
       "      <td>13.0</td>\n",
       "      <td>102478.0</td>\n",
       "      <td>gen1</td>\n",
       "      <td>High</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.694897</td>\n",
       "      <td>-5.827349</td>\n",
       "      <td>-1.449851</td>\n",
       "      <td>-0.350315</td>\n",
       "      <td>-0.511595</td>\n",
       "      <td>-2.614036</td>\n",
       "      <td>1.043629</td>\n",
       "      <td>1.750753</td>\n",
       "      <td>0.114332</td>\n",
       "      <td>-0.088321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157434</th>\n",
       "      <td>14.0</td>\n",
       "      <td>102478.0</td>\n",
       "      <td>gen1</td>\n",
       "      <td>High</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.694897</td>\n",
       "      <td>-5.827349</td>\n",
       "      <td>-1.449851</td>\n",
       "      <td>-0.350315</td>\n",
       "      <td>-0.511128</td>\n",
       "      <td>-2.605104</td>\n",
       "      <td>1.058136</td>\n",
       "      <td>1.737135</td>\n",
       "      <td>0.102352</td>\n",
       "      <td>-0.088407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157435</th>\n",
       "      <td>15.0</td>\n",
       "      <td>102478.0</td>\n",
       "      <td>gen1</td>\n",
       "      <td>High</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.694897</td>\n",
       "      <td>-5.827349</td>\n",
       "      <td>-1.449851</td>\n",
       "      <td>-0.350315</td>\n",
       "      <td>-0.508548</td>\n",
       "      <td>-2.607412</td>\n",
       "      <td>1.061236</td>\n",
       "      <td>1.741602</td>\n",
       "      <td>0.098320</td>\n",
       "      <td>-0.088435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157436</th>\n",
       "      <td>16.0</td>\n",
       "      <td>102478.0</td>\n",
       "      <td>gen1</td>\n",
       "      <td>High</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.694897</td>\n",
       "      <td>-5.827349</td>\n",
       "      <td>-1.449851</td>\n",
       "      <td>-0.350315</td>\n",
       "      <td>-0.505553</td>\n",
       "      <td>-2.606696</td>\n",
       "      <td>1.064896</td>\n",
       "      <td>1.724035</td>\n",
       "      <td>0.090007</td>\n",
       "      <td>-0.088494</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>157437 rows × 251 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Timesteps  ChassisId_encoded   gen risk_level    af1__0   af1__1  \\\n",
       "0             0.0             4953.0  gen1       High  0.000000  0.00000   \n",
       "1             0.0             4955.0  gen1        Low  0.000322  0.00002   \n",
       "2             1.0             4955.0  gen1        Low  0.000322  0.00002   \n",
       "3             2.0             4955.0  gen1        Low  0.000322  0.00002   \n",
       "4             3.0             4955.0  gen1        Low  0.000322  0.00002   \n",
       "...           ...                ...   ...        ...       ...      ...   \n",
       "157432       12.0           102478.0  gen1       High  0.000000  0.00000   \n",
       "157433       13.0           102478.0  gen1       High  0.000000  0.00000   \n",
       "157434       14.0           102478.0  gen1       High  0.000000  0.00000   \n",
       "157435       15.0           102478.0  gen1       High  0.000000  0.00000   \n",
       "157436       16.0           102478.0  gen1       High  0.000000  0.00000   \n",
       "\n",
       "          af1__2        af1__3    af1__4    af1__6  ...    f__232    f__233  \\\n",
       "0       0.000000  0.000000e+00  0.000000  0.000000  ... -5.694897 -5.827349   \n",
       "1       0.057749  8.627059e-08  0.029966  0.019837  ...  0.121147  0.230757   \n",
       "2       0.057749  8.627059e-08  0.029966  0.019837  ...  0.121147  0.230757   \n",
       "3       0.057749  8.627059e-08  0.029966  0.019837  ...  0.121147  0.230757   \n",
       "4       0.057749  8.627059e-08  0.029966  0.019837  ...  0.121147  0.230757   \n",
       "...          ...           ...       ...       ...  ...       ...       ...   \n",
       "157432  0.000000  0.000000e+00  0.000000  0.000000  ... -5.694897 -5.827349   \n",
       "157433  0.000000  0.000000e+00  0.000000  0.000000  ... -5.694897 -5.827349   \n",
       "157434  0.000000  0.000000e+00  0.000000  0.000000  ... -5.694897 -5.827349   \n",
       "157435  0.000000  0.000000e+00  0.000000  0.000000  ... -5.694897 -5.827349   \n",
       "157436  0.000000  0.000000e+00  0.000000  0.000000  ... -5.694897 -5.827349   \n",
       "\n",
       "          f__234    f__235    f__237    f__238    f__239    f__240    f__241  \\\n",
       "0      -1.449851 -0.350315  1.394857  0.192880 -0.495562 -0.928794 -0.214402   \n",
       "1       0.280036 -0.206586 -0.088550 -0.836415 -0.484087  0.320285  2.311401   \n",
       "2       0.280036 -0.206586 -0.091570 -0.841418 -0.472325  0.322941  2.284491   \n",
       "3       0.280036 -0.206586 -0.029233 -0.817824 -0.509273  0.306841  2.266275   \n",
       "4       0.280036 -0.206586 -0.002841 -0.808023 -0.513796  0.309057  2.237995   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "157432 -1.449851 -0.350315 -0.513768 -2.615375  1.035627  1.758682  0.122545   \n",
       "157433 -1.449851 -0.350315 -0.511595 -2.614036  1.043629  1.750753  0.114332   \n",
       "157434 -1.449851 -0.350315 -0.511128 -2.605104  1.058136  1.737135  0.102352   \n",
       "157435 -1.449851 -0.350315 -0.508548 -2.607412  1.061236  1.741602  0.098320   \n",
       "157436 -1.449851 -0.350315 -0.505553 -2.606696  1.064896  1.724035  0.090007   \n",
       "\n",
       "          f__242  \n",
       "0      -0.090670  \n",
       "1      -0.026043  \n",
       "2      -0.026732  \n",
       "3      -0.027429  \n",
       "4      -0.028150  \n",
       "...          ...  \n",
       "157432 -0.088263  \n",
       "157433 -0.088321  \n",
       "157434 -0.088407  \n",
       "157435 -0.088435  \n",
       "157436 -0.088494  \n",
       "\n",
       "[157437 rows x 251 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.volvo_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'train_dataset = VolvoDatasetPart2(data_path=train_data_path, variants_path=variants_path)\\nprocessor = train_dataset.get_processor()\\nlabel_encoder = processor.risk_encoder\\n\\ntrain_dataset, validation_dataset = train_dataset.split_train_validation()\\n\\ntest_dataset = VolvoDatasetPart2(data_path=test_data_path, variants_path=variants_path, test=True)\\ntest_dataset.set_processor(processor) '"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"train_dataset = VolvoDatasetPart2(data_path=train_data_path, variants_path=variants_path)\n",
    "processor = train_dataset.get_processor()\n",
    "label_encoder = processor.risk_encoder\n",
    "\n",
    "train_dataset, validation_dataset = train_dataset.split_train_validation()\n",
    "\n",
    "test_dataset = VolvoDatasetPart2(data_path=test_data_path, variants_path=variants_path, test=True)\n",
    "test_dataset.set_processor(processor) \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on cuda\n",
      "Computing class weights...done\n",
      "Class weights =  [0.8785872 0.1214128]\n"
     ]
    }
   ],
   "source": [
    "n_features = train_dataset.get_n_features()\n",
    "num_classes = train_dataset.get_n_classes()\n",
    "\n",
    "#check if preprocess is giving some problems\n",
    "assert train_dataset.get_n_features() == test_dataset.get_n_features()\n",
    "\n",
    "model = SS_TCN(     num_input_channels=n_features, \n",
    "                    num_classes=num_classes, \n",
    "                    is_phase_1=True)\n",
    "\n",
    "### Get device\n",
    "device = torch.device(\n",
    "            \"cuda\" if (torch.cuda.is_available() and not args.disable_cuda) else \"cpu\"\n",
    "        )\n",
    "model.to(device)\n",
    "print(f\"Working on {device}\")\n",
    "\n",
    "# Load weights if necessary\n",
    "if args.load_model != \"\":\n",
    "    if not(args.load_model.endswith(\".pth\") or args.load_model.endswith(\".pt\")):\n",
    "        raise Exception(\"Weights file should end with .pt or .pth\")\n",
    "    model_path = os.join.path(weights_path, args.load_model)\n",
    "    print(f\"Loading Model from {model_path}\")\n",
    "    model.load_state_dict(\n",
    "        torch.load( model_path )\n",
    "    )\n",
    "\n",
    "# Create DataLoader instances for train, validation, and test sets\n",
    "train_loader = DataLoader(train_dataset, \n",
    "                                batch_size=args.batch_size, \n",
    "                                shuffle=True,\n",
    "                                num_workers=12) #pin_memory=True #consigliano\n",
    "val_loader = DataLoader(validation_dataset, \n",
    "                                batch_size=args.batch_size, \n",
    "                                shuffle=True,\n",
    "                                num_workers=12)\n",
    "test_loader =  DataLoader(test_dataset, \n",
    "                                batch_size=args.batch_size)\n",
    "\n",
    "# Define criterion\n",
    "print('Computing class weights...', end='')\n",
    "weights = train_dataset.get_weights()\n",
    "criterion = BCELoss(weight=torch.Tensor(weights).to(device))\n",
    "optimizer = optim.Adam(model.parameters(), lr=args.learning_rate)\n",
    "print('done')\n",
    "print('Class weights = ', weights)\n",
    "# criterion = ContinuityCrossEntropyLoss(weights=torch.Tensor([1,1,1]).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Start training ===\n",
      "Batch size: 256\n",
      "========================= EPOCH 0 =========================\n",
      "Learning rate:  0.0005\n",
      "=== TRAIN ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running loss: 0.0:   0%|          | 0/74 [00:03<?, ?it/s]/home/grosso/.conda/envs/jack_predicting-failure-risk-levels/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "Running loss: 0.3269:  97%|█████████▋| 72/74 [00:26<00:00,  4.61it/s]/home/grosso/.conda/envs/jack_predicting-failure-risk-levels/lib/python3.12/site-packages/torch/autograd/graph.py:744: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "Running loss: 0.3269: 100%|██████████| 74/74 [00:26<00:00,  2.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/30], Train Loss: 0.3261\n",
      "=== VAL ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running loss: 0.0: 100%|██████████| 19/19 [00:07<00:00,  2.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.98990363 0.84397163]\n",
      "[0.98990363 0.84397163]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      4344\n",
      "           1       0.89      0.80      0.84       296\n",
      "\n",
      "    accuracy                           0.98      4640\n",
      "   macro avg       0.94      0.90      0.92      4640\n",
      "weighted avg       0.98      0.98      0.98      4640\n",
      "\n",
      "Average discontinuity = 25.47\n",
      "More than max = tensor([0.0000, 5.5789, 0.0000])\n",
      "F1 score = 0.92\n",
      "\n",
      "Validation Accuracy: 239.5789\n",
      "Validation Loss: 0.0000 vs Best inf\n",
      "Validation F1: 0.92 vs Best 0\n",
      "========================= EPOCH 1 =========================\n",
      "Learning rate:  0.0004\n",
      "=== TRAIN ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running loss: 0.2571:  49%|████▊     | 36/74 [00:17<00:18,  2.01it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 20\u001b[0m\n\u001b[1;32m     18\u001b[0m running_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     19\u001b[0m i \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m---> 20\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtimeseries\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvariants\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpbar\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpbar\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_description\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mRunning loss: \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mrunning_loss\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1e-5\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;250;43m \u001b[39;49m\u001b[38;5;132;43;01m:\u001b[39;49;00m\u001b[38;5;124;43m.4\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeseries\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvariants\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtimeseries\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvariants\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/jack_predicting-failure-risk-levels/lib/python3.12/site-packages/tqdm/std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1181\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   1182\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[1;32m   1183\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[1;32m   1184\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "File \u001b[0;32m~/.conda/envs/jack_predicting-failure-risk-levels/lib/python3.12/site-packages/torch/utils/data/dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/.conda/envs/jack_predicting-failure-risk-levels/lib/python3.12/site-packages/torch/utils/data/dataloader.py:1329\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data)\n\u001b[1;32m   1328\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m-> 1329\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1330\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1331\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[1;32m   1332\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/jack_predicting-failure-risk-levels/lib/python3.12/site-packages/torch/utils/data/dataloader.py:1295\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1291\u001b[0m     \u001b[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[1;32m   1292\u001b[0m     \u001b[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[1;32m   1293\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1294\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m-> 1295\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1296\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[1;32m   1297\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/.conda/envs/jack_predicting-failure-risk-levels/lib/python3.12/site-packages/torch/utils/data/dataloader.py:1133\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1120\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_try_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m_utils\u001b[38;5;241m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[1;32m   1121\u001b[0m     \u001b[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[1;32m   1122\u001b[0m     \u001b[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1130\u001b[0m     \u001b[38;5;66;03m# Returns a 2-tuple:\u001b[39;00m\n\u001b[1;32m   1131\u001b[0m     \u001b[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1133\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1134\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n\u001b[1;32m   1135\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1136\u001b[0m         \u001b[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[1;32m   1137\u001b[0m         \u001b[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[1;32m   1138\u001b[0m         \u001b[38;5;66;03m# worker failures.\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/jack_predicting-failure-risk-levels/lib/python3.12/multiprocessing/queues.py:113\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m block:\n\u001b[1;32m    112\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m deadline \u001b[38;5;241m-\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic()\n\u001b[0;32m--> 113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    114\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_poll():\n",
      "File \u001b[0;32m~/.conda/envs/jack_predicting-failure-risk-levels/lib/python3.12/multiprocessing/connection.py:257\u001b[0m, in \u001b[0;36m_ConnectionBase.poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_closed()\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_readable()\n\u001b[0;32m--> 257\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/jack_predicting-failure-risk-levels/lib/python3.12/multiprocessing/connection.py:440\u001b[0m, in \u001b[0;36mConnection._poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_poll\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout):\n\u001b[0;32m--> 440\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    441\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(r)\n",
      "File \u001b[0;32m~/.conda/envs/jack_predicting-failure-risk-levels/lib/python3.12/multiprocessing/connection.py:1136\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     deadline \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic() \u001b[38;5;241m+\u001b[39m timeout\n\u001b[1;32m   1135\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m-> 1136\u001b[0m     ready \u001b[38;5;241m=\u001b[39m \u001b[43mselector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1137\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ready:\n\u001b[1;32m   1138\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [key\u001b[38;5;241m.\u001b[39mfileobj \u001b[38;5;28;01mfor\u001b[39;00m (key, events) \u001b[38;5;129;01min\u001b[39;00m ready]\n",
      "File \u001b[0;32m~/.conda/envs/jack_predicting-failure-risk-levels/lib/python3.12/selectors.py:415\u001b[0m, in \u001b[0;36m_PollLikeSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m ready \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    414\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 415\u001b[0m     fd_event_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_selector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpoll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    416\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n\u001b[1;32m    417\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ready\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(\"=== Start training ===\")\n",
    "print(f\"Batch size: {args.batch_size}\")\n",
    "# Define loss function and optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=args.learning_rate)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, gamma=args.lr_scheduler_gamma, step_size=args.lr_scheduler_step)\n",
    "softmax = torch.nn.functional.softmax\n",
    "waiting_epochs = 0\n",
    "best_val_loss = float('inf')\n",
    "best_val_f1 = 0\n",
    "num_resets = 0\n",
    "for epoch in range(args.num_epochs):\n",
    "    ### Run epoch\n",
    "    print( \"=\"*25, f\"EPOCH {epoch}\", \"=\"*25)\n",
    "    print(\"Learning rate: \", optimizer.param_groups[0]['lr'])\n",
    "    print(\"=== TRAIN ===\")\n",
    "    model.train()     \n",
    "    pbar = tqdm.tqdm(train_loader)\n",
    "    running_loss = 0\n",
    "    i = 0\n",
    "    for timeseries, variants, labels in pbar:\n",
    "        pbar.set_description(f\"Running loss: {running_loss/(i+1e-5) :.4}\")\n",
    "        timeseries, variants, labels = timeseries.to(device), variants.to(device), labels.to(device)\n",
    "        outputs = model(timeseries, variants)\n",
    "        outputs = softmax(outputs, dim=-1)\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        i += 1\n",
    "\n",
    "    epoch_loss = running_loss / (i+1e-5)\n",
    "    scheduler.step()\n",
    "    print(f\"Epoch [{epoch+1}/{args.num_epochs}], Train Loss: {epoch_loss:.4f}\")\n",
    "\n",
    "    print(\"=== VAL ===\")\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        pbar = tqdm.tqdm(val_loader)\n",
    "        running_loss = 0\n",
    "        running_acc = 0\n",
    "        i = 0\n",
    "        stats = StatsComputer()\n",
    "        for timeseries, variants, labels in pbar:\n",
    "            pbar.set_description(f\"Running loss: {running_loss/(i+1e-5) :.4}\")\n",
    "            \n",
    "            timeseries, variants, labels = timeseries.to(device), variants.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(timeseries, variants)\n",
    "            outputs = softmax(outputs, dim=-1)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # outputs = outputs[-1]\n",
    "            acc = torch.sum(torch.argmax(labels, dim = 1) == torch.argmax(outputs, dim = 1))\n",
    "            \n",
    "            running_acc += acc \n",
    "\n",
    "            stats.append(outputs=torch.argmax(outputs, dim=-1).cpu().tolist(), \n",
    "                        labels=torch.argmax(labels, dim=-1).cpu().tolist())\n",
    "\n",
    "            i += 1\n",
    "\n",
    "        validation_loss = running_loss / i\n",
    "        validation_accuracy = running_acc / i\n",
    "        \n",
    "        validation_f1 = stats.macro_avg_f1()\n",
    "        print(stats)\n",
    "    \n",
    "    print(f\"Validation Accuracy: {validation_accuracy:.4f}\")\n",
    "    print(f\"Validation Loss: {validation_loss:.4f} vs Best {best_val_loss:.4f}\")\n",
    "    print(f\"Validation F1: {validation_f1} vs Best {best_val_f1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 4, got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mflatten\u001b[39m(xss):\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [x \u001b[38;5;28;01mfor\u001b[39;00m xs \u001b[38;5;129;01min\u001b[39;00m xss \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m xs]\n\u001b[0;32m----> 5\u001b[0m precision, recall, f1, true_sum \u001b[38;5;241m=\u001b[39m precision_recall_fscore_support(flatten(stats\u001b[38;5;241m.\u001b[39mall_labels), flatten(stats\u001b[38;5;241m.\u001b[39mall_outputs)),\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 4, got 1)"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, precision_recall_fscore_support\n",
    "def flatten(xss):\n",
    "    return [x for xs in xss for x in xs]\n",
    "    \n",
    "precision, recall, f1, true_sum = precision_recall_fscore_support(flatten(stats.all_labels), flatten(stats.all_outputs)),"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
